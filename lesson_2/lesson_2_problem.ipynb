{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LESSON 2: Informed Search Strategies\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "### Maze Environments\n",
    "The environments used is **SmallMaze** (visible in the figure).\n",
    "\n",
    "<img src=\"images/maze.png\" width=\"300\">\n",
    "\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$.\n",
    "\n",
    "### Priority Queue\n",
    "\n",
    "You will need a queue ordered by priority as queue, or **PriorityQueue**. The difference between the other versions of queue is that in **PriorityQueue** nodes are removed from the queue based on the current lowest value. In particular, **Node** has two useful parameters (other than those used in the previous session):\n",
    "\n",
    "- pathcost - the path cost from the root node to the current one (defaults to 0)\n",
    "- value - value of a node. Used by PriorityQueue to order its content (defaults to 0)\n",
    "\n",
    "Here is an example of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed: 1\n",
      "Removed: 3\n",
      "Removed: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.ai_lab_functions import *\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = Node(1) # No parent, pathcost=0, value=0\n",
    "node_2 = Node(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, pathcost=1, value=10\n",
    "node_3 = Node(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_queue = PriorityQueue()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_queue.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_queue.is_empty():\n",
    "    print(\"Removed: {}\".format(p_queue.remove().state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the queue.\n",
    "\n",
    "### Uniform-Cost Search (UCS)\n",
    "Before moving to informed search it is useful to see another uninformed search algorithm: the Uniform-Cost Search (UCS). In the following you can see the implementation in graph search version. Cost of performing an action is supposd to be 1 (also in the assignements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_with_higher_cost(queue, node):\n",
    "    if (node.state in queue):\n",
    "        if(queue[node.state].value > node.value): return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import envs\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "\n",
    "    start_node = Node(environment.startstate)\n",
    "\n",
    "    explored = set()\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(start_node)\n",
    "    \n",
    "    time_cost  = 0\n",
    "    space_cost = 1\n",
    "    \n",
    "    while not frontier.is_empty():\n",
    "        current_node = frontier.remove()\n",
    "        \n",
    "        # Abbiamo finito\n",
    "        if current_node.state == environment.goalstate: \n",
    "            return build_path(current_node), time_cost, space_cost\n",
    "    \n",
    "        explored.add(current_node.state)\n",
    "        \n",
    "        # Esploriamo gli stati successivi\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            next_node_path_cost = current_node.pathcost + 1\n",
    "            next_node_value = next_node_path_cost\n",
    "\n",
    "            next_state = environment.sample(current_node.state, action)\n",
    "            next_node = Node(next_state, current_node, next_node_path_cost, next_node_value)  \n",
    "            \n",
    "            # Se il nodo non è stato già visitato / sarà visitato\n",
    "            if next_node.state not in frontier and next_node.state not in explored:\n",
    "                frontier.add(next_node)\n",
    "\n",
    "            # Se il nodo è presente con un costo maggiore\n",
    "            elif present_with_higher_cost(frontier, next_node):\n",
    "                frontier.replace(next_node)\n",
    "\n",
    "            time_cost += 1\n",
    "                \n",
    "        space_cost = max(space_cost, len(frontier) + len(explored))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "UNIFORM GRAPH SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 1), (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 60\n",
      "Max n° of nodes in memory: 16\n"
     ]
    }
   ],
   "source": [
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution, time, memory = ucs(env)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\nUNIFORM GRAPH SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution, env)))\n",
    "print(\"N° of nodes explored: {}\".format(time))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to be used in order to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "\n",
    "- *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates\n",
    "- *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates\n",
    "- *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to L1 norm but diagonal moves are also considered\n",
    "\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(Heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(Heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(Heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Greedy Best-First Search\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you are required to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use L1 norm as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by greedy must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory at the same time.\n",
    "\n",
    "Functions to implement:\n",
    "- *greedy_tree_search(environment)*\n",
    "- *greedy_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(environment, heuristic, timeout=10000):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_node = Node(environment.startstate)\n",
    "    goal_state_pos = environment.state_to_pos(environment.goalstate)\n",
    "\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(start_node)\n",
    "\n",
    "    time_cost  = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while not frontier.is_empty():\n",
    "        \n",
    "        # timeout check\n",
    "        if time_cost >= timeout: \n",
    "            return \"time-out\", time_cost, space_cost\n",
    "        \n",
    "        # Se abbiamo raggiunto lo stato finale\n",
    "        current_node = frontier.remove()\n",
    "        if current_node.state == environment.goalstate:\n",
    "            return build_path(current_node), time_cost, space_cost\n",
    "        \n",
    "        # Vediamo i possibili stati successori\n",
    "        for action in range(environment.action_space.n):\n",
    "\n",
    "            next_state = environment.sample(current_node.state, action)\n",
    "            next_state_pos = environment.state_to_pos(next_state)\n",
    "\n",
    "            next_node_path_cost = current_node.pathcost + 1\n",
    "            next_node_value = heuristic(next_state_pos, goal_state_pos) # Euristica\n",
    "\n",
    "            next_node = Node(next_state, current_node, next_node_path_cost, next_node_value)\n",
    "            frontier.add(next_node)\n",
    "\n",
    "            # Se il nodo è presente con un costo maggiore\n",
    "            if present_with_higher_cost(frontier, next_node):\n",
    "                frontier.replace(next_node)\n",
    "\n",
    "            time_cost += 1\n",
    "                \n",
    "        space_cost = max(space_cost, len(frontier))\n",
    "        \n",
    "    return 'failure', time_cost, space_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment, heuristic):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_node = Node(environment.startstate)\n",
    "    goal_state_pos = environment.state_to_pos(environment.goalstate)\n",
    "\n",
    "    explored = set()\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(start_node)\n",
    "\n",
    "    time_cost  = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while not frontier.is_empty():\n",
    "        \n",
    "        # Se abbiamo raggiunto lo stato finale\n",
    "        current_node = frontier.remove()\n",
    "        if current_node.state == environment.goalstate:\n",
    "            return build_path(current_node), time_cost, space_cost\n",
    "        \n",
    "        explored.add(current_node.state)\n",
    "\n",
    "        # Vediamo i possibili stati successori\n",
    "        for action in range(environment.action_space.n):\n",
    "\n",
    "            next_state = environment.sample(current_node.state, action)\n",
    "            next_state_pos = environment.state_to_pos(next_state)\n",
    "\n",
    "            next_node_path_cost = current_node.pathcost + 1\n",
    "            next_node_value = heuristic(next_state_pos, goal_state_pos) # Euristica\n",
    "\n",
    "            # Se il nodo non è stato già visitato / sarà visitato\n",
    "            next_node = Node(next_state, current_node, next_node_path_cost, next_node_value)\n",
    "            if next_node.state not in frontier and next_node.state not in explored:\n",
    "                frontier.add(next_node)\n",
    "\n",
    "            # Se il nodo è presente con un costo maggiore\n",
    "            elif present_with_higher_cost(frontier, next_node):\n",
    "                frontier.replace(next_node)\n",
    "\n",
    "            time_cost += 1\n",
    "                \n",
    "        space_cost = max(space_cost, len(frontier) + len(explored))\n",
    "        \n",
    "    return 'failure', time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calls your implementations of greedy_tree_search and greedy_graph_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, heuristic, search_type):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment, heuristic)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search and graph search version of Greedy-best-first search and prints the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tGREEDY BEST FIRST TREE SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: time-out\n",
      "N° of nodes explored: 10000\n",
      "Max n° of nodes in memory: 7501\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\tGREEDY BEST FIRST GRAPH SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 3), (1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 44\n",
      "Max n° of nodes in memory: 15\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "heuristic = Heu.l2_norm\n",
    "\n",
    "solution_ts, time_ts, memory_ts = greedy(environment, heuristic, greedy_tree_search)\n",
    "solution_gs, time_gs, memory_gs = greedy(environment, heuristic, greedy_graph_search)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGREEDY BEST FIRST TREE SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_ts, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_ts))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_ts))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tGREEDY BEST FIRST GRAPH SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_gs, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_gs))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results can be found [here](lesson_2_results.txt).\n",
    "\n",
    "## Assignment 2: A* Search\n",
    "The second assignment is to implement the A search algorithm on SmallMaze. In particular, you are required to implement both astar_tree_search and astar_graph_search versions that will be called by the generic astar. Use L1 norm* as heuristic function at first, then try also the others to see the differences.\n",
    "\n",
    "The results returned by astar must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory at the same time.\n",
    "\n",
    "Functions to implement:\n",
    "- *astar_tree_search(environment)*\n",
    "- *astar_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_node = Node(environment.startstate)\n",
    "    goal_state_pos = environment.state_to_pos(environment.goalstate)\n",
    "\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(start_node)\n",
    "\n",
    "    time_cost  = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while not frontier.is_empty():\n",
    "        \n",
    "        # Se abbiamo raggiunto lo stato finale\n",
    "        current_node = frontier.remove()\n",
    "        if current_node.state == environment.goalstate:\n",
    "            return build_path(current_node), time_cost, space_cost\n",
    "        \n",
    "        # Vediamo i possibili stati successori\n",
    "        for action in range(environment.action_space.n):\n",
    "\n",
    "            next_state = environment.sample(current_node.state, action)\n",
    "            next_state_pos = environment.state_to_pos(next_state)\n",
    "\n",
    "            next_node_path_cost = current_node.pathcost + 1\n",
    "            next_node_value = next_node_path_cost + Heu.l1_norm(next_state_pos, goal_state_pos) # Euristica\n",
    "\n",
    "            next_node = Node(next_state, current_node, next_node_path_cost, next_node_value)\n",
    "            frontier.add(next_node)\n",
    "\n",
    "            # Se il nodo è presente con un costo maggiore\n",
    "            if present_with_higher_cost(frontier, next_node):\n",
    "                frontier.replace(next_node)\n",
    "\n",
    "            time_cost += 1\n",
    "                \n",
    "        space_cost = max(space_cost, len(frontier))\n",
    "        \n",
    "    return 'failure', time_cost, space_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment):\n",
    "    \"\"\"\n",
    "    A* Graph search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    start_node = Node(environment.startstate)\n",
    "    goal_state_pos = environment.state_to_pos(environment.goalstate)\n",
    "\n",
    "    explored = set()\n",
    "    frontier = PriorityQueue()\n",
    "    frontier.add(start_node)\n",
    "\n",
    "    time_cost  = 0\n",
    "    space_cost = 1\n",
    "\n",
    "    while not frontier.is_empty():\n",
    "        \n",
    "        # Se abbiamo raggiunto lo stato finale\n",
    "        current_node = frontier.remove()\n",
    "        if current_node.state == environment.goalstate:\n",
    "            return build_path(current_node), time_cost, space_cost\n",
    "        \n",
    "        explored.add(current_node.state)\n",
    "\n",
    "        # Vediamo i possibili stati successori\n",
    "        for action in range(environment.action_space.n):\n",
    "\n",
    "            next_state = environment.sample(current_node.state, action)\n",
    "            next_state_pos = environment.state_to_pos(next_state)\n",
    "\n",
    "            next_node_path_cost = current_node.pathcost + 1\n",
    "            next_node_value = next_node_path_cost + Heu.l1_norm(next_state_pos, goal_state_pos) # Euristica\n",
    "\n",
    "            # Se il nodo non è stato già visitato / sarà visitato\n",
    "            next_node = Node(next_state, current_node, next_node_path_cost, next_node_value)\n",
    "            if next_node.state not in frontier and next_node.state not in explored:\n",
    "                frontier.add(next_node)\n",
    "\n",
    "            # Se il nodo è presente con un costo maggiore\n",
    "            elif present_with_higher_cost(frontier, next_node):\n",
    "                frontier.replace(next_node)\n",
    "\n",
    "            time_cost += 1\n",
    "                \n",
    "        space_cost = max(space_cost, len(frontier) + len(explored))\n",
    "        \n",
    "    return 'failure', time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calls your implementations of astar_tree_search and astar_graph_search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code calls your tree search and graph search version of A* search and prints the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tA* TREE SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 8360\n",
      "Max n° of nodes in memory: 6271\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\tA* GRAPH SEARCH PROBLEM: \n",
      "----------------------------------------------------------------\n",
      "Solution: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 60\n",
      "Max n° of nodes in memory: 16\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "solution_ts, time_ts, memory_ts = astar(environment, astar_tree_search)\n",
    "solution_gs, time_gs, memory_gs = astar(environment, astar_graph_search)\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tA* TREE SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_ts, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_ts))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_ts))\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tA* GRAPH SEARCH PROBLEM: \")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"Solution: {}\".format(solution_2_string(solution_gs, environment)))\n",
    "print(\"N° of nodes explored: {}\".format(time_gs))\n",
    "print(\"Max n° of nodes in memory: {}\".format(memory_gs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results can be found [here](lesson_2_results.txt).\n",
    "\n",
    "### Discussion\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
